import torch
import cv2
import numpy as np
from PIL import Image
import io
from ultralytics import YOLO
import os

# === PyTorch 2.6 í˜¸í™˜ì„±ì„ ìœ„í•œ ì„¤ì • ===
# torch.loadì˜ weights_onlyë¥¼ Falseë¡œ ì„¤ì •
torch.serialization.DEFAULT_PROTOCOL = 2

class LeafSegmentationModel:
    
    def __init__(self, model_path: str):
        """
        ì ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            model_path (str): seg_best.pt ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        """
        self.model_path = model_path
        self.model = None
        self.device = self._get_device()
        self._load_model()
    
    def _get_device(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ ê²°ì •"""
        if torch.cuda.is_available():
            return "cuda"
        elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
            return "mps"
        else:
            return "cpu"
    
    def _load_model(self):
        """YOLO ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë“œ"""
        try:
            # PyTorch 2.6 í˜¸í™˜ì„±ì„ ìœ„í•œ ì„¤ì •
            import torch
            import pickle
            
            # torch.loadë¥¼ ì„ì‹œë¡œ ìˆ˜ì •
            original_load = torch.load
            original_pickle_load = pickle.load
            
            def safe_torch_load(*args, **kwargs):
                kwargs['weights_only'] = False
                return original_load(*args, **kwargs)
            
            def safe_pickle_load(*args, **kwargs):
                # pickleì˜ ë³´ì•ˆ ì„¤ì • ì™„í™”
                import pickle
                original_pickle_loads = pickle.loads
                def safe_loads(data):
                    return original_pickle_loads(data)
                pickle.loads = safe_loads
                try:
                    return original_pickle_load(*args, **kwargs)
                finally:
                    pickle.loads = original_pickle_loads
            
            torch.load = safe_torch_load
            pickle.load = safe_pickle_load
            
            # ëª¨ë¸ ë¡œë“œ
            # weights_only=Falseë¡œ ëª¨ë¸ ë¡œë”©
            original_load = torch.load
            torch.load = lambda *args, **kwargs: original_load(*args, **kwargs, weights_only=False)
            
            self.model = YOLO(self.model_path)
            
            # ì›ë˜ í•¨ìˆ˜ë“¤ ë³µì›
            torch.load = original_load
            pickle.load = original_pickle_load
            
            print(f"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_path}")
            print(f"ğŸ”§ Device: {self.device}")
            
            # ì›ë˜ torch.load ë³µì›
            torch.load = original_load
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ì›ë˜ í•¨ìˆ˜ë“¤ ë³µì› (ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„)
            try:
                torch.load = original_load
                pickle.load = original_pickle_load
            except:
                pass
            raise e
    
    def predict(self, image_input):
        """
        ì´ë¯¸ì§€ì—ì„œ ìì„ íƒì§€í•˜ê³  ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
        
        Args:
            image_input: PIL Image, numpy array, ë˜ëŠ” íŒŒì¼ ê²½ë¡œ
            
        Returns:
            dict: {
                'segmented_image': PIL Image,
                'cropped_leaves': list of PIL Images,
                'masks': list of numpy arrays,
                'boxes': list of bounding boxes
            }
        """
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            if isinstance(image_input, str):
                # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
                image = Image.open(image_input)
            elif isinstance(image_input, np.ndarray):
                # numpy arrayì¸ ê²½ìš°
                image = Image.fromarray(cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB))
            else:
                # PIL Imageì¸ ê²½ìš°
                image = image_input
            
            # YOLO ëª¨ë¸ë¡œ ì˜ˆì¸¡
            results = self.model(image)
            
            # ê²°ê³¼ ì²˜ë¦¬
            segmented_image, cropped_leaves, masks, boxes = self._process_results(image, results[0])
            
            return {
                'segmented_image': segmented_image,
                'cropped_leaves': cropped_leaves,
                'masks': masks,
                'boxes': boxes
            }
            
        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            raise e
    
    def _process_results(self, original_image, result):
        """
        YOLO ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ì—¬ ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ì™€ í¬ë¡­ëœ ìë“¤ì„ ìƒì„±
        
        Args:
            original_image: ì›ë³¸ PIL Image
            result: YOLO ê²°ê³¼ ê°ì²´
            
        Returns:
            tuple: (segmented_image, cropped_leaves, masks, boxes)
        """
        # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ numpy arrayë¡œ ë³€í™˜
        img_array = np.array(original_image)
        height, width = img_array.shape[:2]
        
        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ ì´ˆê¸°í™”
        segmented_mask = np.zeros((height, width), dtype=np.uint8)
        
        cropped_leaves = []
        masks = []
        boxes = []
        
        if result.masks is not None:
            for i, mask in enumerate(result.masks.data):
                # ë§ˆìŠ¤í¬ë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                mask_resized = cv2.resize(
                    mask.cpu().numpy(), 
                    (width, height), 
                    interpolation=cv2.INTER_NEAREST
                )
                
                # ë§ˆìŠ¤í¬ë¥¼ 0-255 ë²”ìœ„ë¡œ ì •ê·œí™”
                mask_normalized = (mask_resized * 255).astype(np.uint8)
                masks.append(mask_normalized)
                
                # ì „ì²´ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ì— ì¶”ê°€
                segmented_mask = cv2.bitwise_or(segmented_mask, mask_normalized)
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
                contours, _ = cv2.findContours(mask_normalized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                if contours:
                    x, y, w, h = cv2.boundingRect(contours[0])
                    boxes.append([x, y, x+w, y+h])
                    
                    # ì ë¶€ë¶„ë§Œ í¬ë¡­
                    cropped_leaf = img_array[y:y+h, x:x+w]
                    if cropped_leaf.size > 0:
                        cropped_leaves.append(Image.fromarray(cropped_leaf))
        
        # ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€ ìƒì„± (ì›ë³¸ + ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´)
        segmented_image = self._create_segmented_image(img_array, segmented_mask)
        
        return segmented_image, cropped_leaves, masks, boxes
    
    def _create_segmented_image(self, original_img, mask):
        """
        ì›ë³¸ ì´ë¯¸ì§€ì— ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ë¥¼ ì˜¤ë²„ë ˆì´í•œ ì´ë¯¸ì§€ ìƒì„±
        
        Args:
            original_img: ì›ë³¸ ì´ë¯¸ì§€ (numpy array)
            mask: ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ (numpy array)
            
        Returns:
            PIL Image: ì„¸ê·¸ë©˜í…Œì´ì…˜ëœ ì´ë¯¸ì§€
        """
        # ì»¬ëŸ¬ ë§ˆìŠ¤í¬ ìƒì„± (ë…¹ìƒ‰ìœ¼ë¡œ ì ë¶€ë¶„ í‘œì‹œ)
        colored_mask = np.zeros_like(original_img)
        colored_mask[:, :, 1] = mask  # ë…¹ìƒ‰ ì±„ë„ì— ë§ˆìŠ¤í¬ ì ìš©
        
        # ì›ë³¸ ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ë¥¼ ë¸”ë Œë”©
        alpha = 0.3  # íˆ¬ëª…ë„
        segmented_img = cv2.addWeighted(original_img, 1-alpha, colored_mask, alpha, 0)
        
        return Image.fromarray(segmented_img)
    
    def save_cropped_leaves(self, cropped_leaves, output_dir="cropped_leaves"):
        """
        í¬ë¡­ëœ ì ì´ë¯¸ì§€ë“¤ì„ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            cropped_leaves: í¬ë¡­ëœ ì ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬
            
        Returns:
            list: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œë“¤
        """
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        saved_paths = []
        for i, leaf_img in enumerate(cropped_leaves):
            filename = f"leaf_{i+1}.jpg"
            filepath = os.path.join(output_dir, filename)
            leaf_img.save(filepath, "JPEG", quality=95)
            saved_paths.append(filepath)
        
        return saved_paths
